# This workflow is intended to be run with the --sdm=conda option,
# and most rules require either the sc2ts or pangolin environments.
# The base conda environment that snakemake is run from requires
# snakemake, tszip, pandas and tqdm in order to run the "run"
# rules (which cannot be used with "conda")

rule all:
    input:
        # Small for pipeline dev
        # "sc2ts_v1_2020-06-21_pp_dels_bps_pango_dated_mm.trees.tsz",
        "logs/sc2ts_v1_2023-02-21_debug-report.ipynb",
        "logs/sc2ts_v1_2023-02-21_pp_dels_deletion-report.ipynb",
        "logs/usher_sc2ts_comparison.ipynb",
        "sc2ts_v1_2023-02-21_pp_dels_bps_pango_dated_mmps.trees.tsz",
        # Full usher tree with mutations, but uncalibrated node time
        "usher_v1_2024-06-06_mm.trees.tsz",
        # Usher intersection with sc2ts, with dated nodes
        "usher_2023-02-21_intersection_ds_di.trees.tsz",
        # Sc2ts intersection, not dated (annoying metdata issues)
        "sc2ts_2023-02-21_intersection.trees.tsz",
        # All-sites parsimony files, to get the direct comparison
        "usher_2023-02-21_intersection_asp.trees",
        "sc2ts_2023-02-21_intersection_asp.trees",


rule initialise:
    input:
        "../inference/results/v1-beta1/v1-beta1_{DATE}.ts",
    output:
        "sc2ts_v1_{DATE}.trees",
    shell:
        """
        cp {input} {output}
        """

rule debug_report:
    conda:
        "sc2ts.yml"
    input:
        "{DR_PREFIX}.trees",
    log:
        notebook="logs/{DR_PREFIX}_debug-report.ipynb"
    notebook:
        "notebooks/debug_report.py.ipynb"


# Add exact matches to the dataset and do some minor mutation
# rearrangements like pushing unary recombinant mutations.
rule postprocess:
    conda:
        "sc2ts.yml"
    input:
        "{PP_PREFIX}.trees"
    output:
        "{PP_PREFIX}_pp.trees",
    shell:
        """
        python -m sc2ts postprocess {input} {output} \
            --match-db=../inference/results/v1-beta1.matches.db
        """

# NOTE: this rule should be renamed to be more general if we 
# do map sites not just for dels but things we omit also
rule map_deletions:
    conda:
        "sc2ts.yml"
    input:
        "../data/viridian_mafft_2024-10-14_v1.vcz.zip",
        "{MD_PREFIX}.trees",
        "deletion_sites.txt",
    output:
        "{MD_PREFIX}_dels.trees",
        "{MD_PREFIX}_dels_parsimony.csv",
    shell:
        """
        python -m sc2ts map-parsimony -vv \
            {input[0]} {input[1]} {output[0]} \
            --sites={input[2]} --report={output[1]} --no-progress
        """

rule deletion_report:
    conda:
        "sc2ts.yml"
    input:
        "{DELR_PREFIX}.trees",
        "{DELR_PREFIX}_parsimony.csv",
    output:
        "{DELR_PREFIX}_deletion_events.csv",
    log:
        notebook="logs/{DELR_PREFIX}_deletion-report.ipynb"
    notebook:
        "notebooks/deletion_report.py.ipynb"


rule shift_breakpoints:
    conda:
        "sc2ts.yml"
    input:
        "{BP_PREFIX}.trees",
    output:
        "{BP_PREFIX}_bps.trees",
    log:
        "{BP_PREFIX}_shift_breakpoints.log",
    shell:
        """
        python ../scripts/run_breakpoint_shift_for_deletions.py -v {input} {output} > {log} 2>&1
        """


rule date:
    conda:
        "sc2ts.yml"
    input:
        "{DATE_PREFIX}.trees",
    output:
        "{DATE_PREFIX}_dated.trees",
    shell:
        """
        python ../scripts/run_nonsample_dating.py {input} {output}
        """


rule tszip:
    conda:
        "sc2ts.yml"
    input:
        "{TSZIP_PREFIX}.trees",
    output:
        "{TSZIP_PREFIX}.trees.tsz",
    shell:
        """
        python -m tszip -k {input} 
        """


rule write_fasta:
    input:
        "{WF_PREFIX}.trees",
    output:
        "{WF_PREFIX}.fasta",
    run:
        import tszip
        import tskit
        import numpy as np

        # Set all nodes to be sample nodes.
        ts = tszip.load(input[0])
        tables = ts.dump_tables()
        node_flags = tables.nodes.flags
        node_flags[:] = tskit.NODE_IS_SAMPLE
        tables.nodes.flags = node_flags
        ts = tables.tree_sequence()
        if ~np.all(ts.nodes_flags == tskit.NODE_IS_SAMPLE):
            raise ValueError("Not all the nodes are samples.")
        samples = np.arange(ts.num_nodes)
        with open(f"{output}", "w") as f:
            # NOTE: this takes about 80G of RAM to do in one go. Can split
            # into chunks of nodes to make it more managable
            for j, entry in enumerate(ts.alignments(samples=samples, left=1)):
                f.write(f">n{samples[j]}\n")
                f.write(entry + "\n")


rule run_pangolin:
    conda:
        "pangolin.yml"
    input:
        "{RP_PREFIX}.fasta",
    output:
        "{RP_PREFIX}.lineage_report.csv",
    shell:
        # Keep the temp files in a local directory pangolin_tmp because we create
        # several copies of the data during the process of running it.
        """
        mkdir -p pangolin_tmp
        pangolin -t {workflow.cores} {input} --tempdir=pangolin_tmp --outfile={output}
        """


rule add_pangolin_metadata:
    input:
        "{APM_PREFIX}.trees",
        "{APM_PREFIX}.lineage_report.csv",
    output:
        "{APM_PREFIX}_pango.trees",
    run:
        import tskit
        import pandas as pd
        import tqdm

        df = pd.read_csv(input[1]).set_index("taxon")
        # Remove NaNs from missing scorpio calls
        df.scorpio_call.fillna(".")
        tables = tskit.TableCollection.load(input[0])
        nodes = tables.nodes.copy()
        tables.nodes.clear()

        for u, row in enumerate(tqdm.tqdm(nodes)):
            record = df.loc[f"n{u}"]
            row.metadata["pango"] = record["lineage"]
            row.metadata["scorpio"] = record["scorpio_call"]
            tables.nodes.append(row)

        tables.dump(f"{output}")


rule minimise_metadata_pango_scorpio:
    conda:
        "sc2ts.yml"
    input:
        "{MM_PREFIX}.trees",
    output:
        "{MM_PREFIX}_mmps.trees",
    shell:
        # Convert the output of the add pangolin metadata command above
        """
        python -m sc2ts minimise-metadata {input} {output} \
            -m strain sample_id -m pango pango -m scorpio scorpio
        """


rule minimise_metadata_date:
    conda:
        "sc2ts.yml"
    input:
        "{MM_PREFIX}.trees",
    output:
        "{MM_PREFIX}_mmd.trees",
    shell:
        # Add the Date_tree to the minimal metadata 
        """
        python -m sc2ts minimise-metadata {input} {output} \
            -m strain sample_id -m Date_tree Date_tree
        """


rule minimise_metadata:
    conda:
        "sc2ts.yml"
    input:
        "{MM_PREFIX}.trees",
    output:
        "{MM_PREFIX}_mm.trees",
    shell:
        # Minimal metadata, just keep sample_id
        """
        python -m sc2ts minimise-metadata {input} {output}
        """


########################
# Usher tree conversion
########################

rule download_json:
    output:
        "tree.all_viridian.202409.jsonl.gz"
    shell:
        """
        wget --quiet --content-disposition \
            https://figshare.com/ndownloader/files/49691040 \
            -O {output}
        """

rule download_pb:
    output:
        "tree.all_viridian.202409.pb.gz"
    shell:
        """
        wget --quiet --content-disposition \
            https://figshare.com/ndownloader/files/49691037 \
            -O {output}
        """

rule export_mutations_local:
    conda:
        # The pangolin environment above also contains a full copy
        # of Usher/matutils, so no point in redoing that.
        "pangolin.yml"
    input:
        "tree.all_viridian.202409.pb.gz"
    output:
        "usher_mutations.tsv"
    shell:
        # Got GTF from 
        # http://hgdownload.soe.ucsc.edu/goldenPath/wuhCor1/bigZips/genes/ncbiGenes.gtf.gz
        """
        matUtils summary -i tree.all_viridian.202409.pb.gz \
            -f reference.fasta -g ncbiGenes.gtf \
            --translate usher_mutations.tsv
        """

rule convert_topology:
    conda:
        "sc2ts.yml"
    input:
        "tree.all_viridian.202409.jsonl.gz"
    output:
        "usher_topology.trees"
    shell:
        "python ../src/mat2tsk.py convert-topology {input} {output}"

rule add_mutations:
    conda:
        "sc2ts.yml"
    input:
        "usher_topology.trees",
        "usher_mutations.tsv"
    output:
        "usher_v1_2024-06-06.trees"
    shell:
        """
        python ../src/mat2tsk.py convert-mutations {input} reference.fasta {output}
        """

rule date_samples:
    conda:
        "sc2ts.yml"
    input:
        # Note: call with e.g. snakemake usher_v1_2024-06-06_ds.trees
        "{DS_PREFIX}.trees",
    output:
        "{DS_PREFIX}_ds.trees",
    shell:
        """
        python ../src/mat2tsk.py date-samples {input} {output}
        """

rule date_internal_nodes:
    conda:
        "sc2ts.yml"
    input:
        # Note: call with e.g. snakemake usher_v1_2024-06-06_ds_di.trees
        "{DI_PREFIX}.trees"
    output:
        "{DI_PREFIX}_di.trees"
    shell:
        """
        echo "NOTE: tsdate can take many minutes per EP iteration: this may be a while."
        python ../src/mat2tsk.py date-internal {input} {output}
        """

rule sc2ts_usher_intersection:
    conda:
        "sc2ts.yml"
    input:
        "usher_v1_2024-06-06_mmd.trees",
        "sc2ts_v1_2023-02-21_mm.trees"
    output:
        "usher_2023-02-21_intersection.trees",
        "sc2ts_2023-02-21_intersection.trees",
    shell:
        """
        python ../src/mat2tsk.py intersect {input} {output}
        """


rule all_sites_parsimony:
    conda:
        "sc2ts.yml"
    input:
        "../data/viridian_mafft_2024-10-14_v1.vcz.zip",
        "{ASP_PREFIX}.trees"
    output:
        "{ASP_PREFIX}_asp.trees",
        "{ASP_PREFIX}_asp.csv"
    shell:
        """
        python -m sc2ts map-parsimony -v {input} {output[0]} \
            --report={output[1]} --no-progress
        """


rule usher_sc2ts_comparison:
    conda:
        "sc2ts.yml"
    input:
        "usher_2023-02-21_intersection.trees",
        "usher_2023-02-21_intersection_asp.trees",
        "usher_2023-02-21_intersection_asp.csv",
        "sc2ts_2023-02-21_intersection.trees",
        "sc2ts_2023-02-21_intersection_asp.trees",
        "sc2ts_2023-02-21_intersection_asp.csv",
    log:
        notebook="logs/usher_sc2ts_comparison.ipynb"
    notebook:
        "notebooks/usher_sc2ts_comparison.py.ipynb"

